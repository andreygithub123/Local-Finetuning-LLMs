# Local-Finetuning-LLMs
This repository displayes the strategy that I used in order to finetune a MISTRAL-7B using a single RTX 4090 Windforce V2 24GB VRAM. This is no way best practices in production, but at least you can get a glimpse of testing your training hypothesis. The pipeline can work with other hyperparameter settings ( thus it make no sense for following this pipeline ).

## Installation guide
````bash
(after making a virtual env)
pip install -r requirements.txt ( it is recommended to use python 3.10 )


![image](https://github.com/user-attachments/assets/4ed2e15a-7c90-4242-bfaf-4e8bf23eadfd)
